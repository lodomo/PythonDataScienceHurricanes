---
title: "Hurricane Analysis (Working Title)"
date: last-modified
author: "Logan MacFarlane and Lorenzo D. Moon"
format: 
    html:
        embed-resources: true
execute:
  echo: false
jupyter: python3
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, ttest_ind, shapiro
from sklearn.linear_model import LinearRegression

df = pd.read_csv("cleaned_hurricane_data.csv")

# Convert into categorical variables
df['basin'] = df['basin'].astype('category')
df['sub_basin'] = df['sub_basin'].astype('category')
df['nature'] = df['nature'].astype('category')
```

## General Background

This dataset provides a comprehensive historical background on tropical cyclones, including hurricanes and typhoons, spanning from 1970 to 2024. It consists of detailed observations that allow for tracking the complete life cycle of individual storms, capturing their paths and changes in intensity over time. Key information recorded for each storm includes its name, a unique identifier, its precise geographical coordinates, the ocean basin of its activity, and critical intensity metrics such as maximum sustained wind speed and minimum central atmospheric pressure.

## Variable Descriptions

| Variable    | Data Type | Description                                      |
|-------------|-----------|--------------------------------------------------|
| object_id   | int64     | Primary Key for each storm                       |
| sid         | string    | Storm identifier                                 |
| basin       | string    | Ocean basin where the storm occurred             |
| sub_basin   | string    | Sub-basin within the ocean basin                 |
| name        | string    | Name of the storm                                |
| nature      | string    | Nature/type of the storm                         |
| year        | int64     | Year of the observation (EST)                    |
| month       | int64     | Month of the observation (EST)                   |
| day         | int64     | Day of the observation   (EST)                   |
| date        | string    | Date of the observation  (GMT/ZULU)              |
| latitude    | float64   | Latitude of the storm's location                 |
| longitude   | float64   | Longitude of the storm's location                |
| usa_wind    | int64     | Maximum sustained wind speed (in whole knots)    |
| usa_pres    | int64     | Minimum central atmospheric pressure (in mb)     |

### Basin Codes

| Code | Description         |
|------|---------------------|
| SI   | South Indian        |
| SP   | South Pacific       |
| WP   | Western Pacific     |
| NI   | North Indian        |
| NAB  | North Atlantic Basin|
| EP   | Eastern Pacific     |
| SA   | South Atlantic      |

### Sub-Basin Codes

| Code | Description        |
|------|--------------------|
| MM   | Malay Archipelago  |
| WA   | Western Australia  |
| EA   | Eastern Australia  |
| BB   | Bay of Bengal      |
| CS   | Caribbean Sea      |
| GM   | Gulf of ~~America~~ Mexico |
| NAB  | North Atlantic Basin|
| AS   | Arabian Sea        |
| CP   | Central Pacific    |

### Nature Variable Codes

| Code | Description          |
|------|----------------------|
| TS   | Tropical Storm       |
| NR   | Not Rated            |
| MX   | Maximum Intensity    |
| ET   | Extratropical        |
| DS   | Dissipating          |
| SS   | Subtropical Storm    |

## Research Questions

**1) Are the most extreme storms (top 10% in a given year) becoming more intense over time?**

**Hypotheses:** 

* **$H_0$**: No increase in intensity of the most extreme storms over time.
* **$H_a1$**: The intensity of the most extreme storms is increasing over time.
* **$H_a2$**: The intensity of the most extreme storms is decreasing over time.

**2) Do the various ocean basins exhibit statistically significant differences in the rate of increase of tropical cyclone frequency?**

**Hypotheses:**

* **$H_0$**: No difference in the rate of increase of tropical cyclone frequency among ocean basins.
* **$H_a$**: At least one ocean basin has a different rate of increase in tropical cyclone frequency compared to others.

## Question 1 Analysis

### Figures and Results

```{python}
# I did it like this to tweak the percentage easily to get desired results.
percentage = 0.10

# Identify the top 25% most intense storms per year
top_percent = df.groupby('year')['usa_wind'].quantile(1 - percentage).reset_index()
top_percent.columns = ['year', 'top_5_wind']

# Filter the original dataframe to include only the top 25% storms
extreme_storms = pd.merge(df, top_percent, on='year')
extreme_storms = extreme_storms[extreme_storms['usa_wind'] >= extreme_storms['top_5_wind']]

# Calculate average intensity of extreme storms per year
avg_intensity_per_year = extreme_storms.groupby('year')['usa_wind'].mean().reset_index()

# Check if this data is normal
stat, p_value = shapiro(avg_intensity_per_year['usa_wind'])
# print(f'Shapiro-Wilk Test: Statistics={stat}, p-value={p_value}')

print("The Shapiro-Wilk test shows the data is ", end="")
if p_value > 0.05:
    print("normally distributed, with p-value =", p_value)
else:
    print("not normally distributed, with p-value =", p_value)

# Do a pearson correlation test
corr, p_value_corr = pearsonr(avg_intensity_per_year['year'], avg_intensity_per_year['usa_wind'])
print("Pearson Correlation shows the data ", end="")
if corr > 0:
    print("has a positive correlation of", corr, "with p-value =", p_value_corr)
else:
    print("has a negative correlation of", corr, "with p-value =", p_value_corr)

if p_value_corr < 0.05:
    print("There is a statistically significant correlation between year and average intensity of extreme storms.")
else:
    print("No statistically significant correlation found between year and average intensity of extreme storms.")

# Plot the extreme storms
sns.regplot(x='year', y='usa_wind', data=avg_intensity_per_year, scatter_kws={'alpha':0.5})
plt.title('Intensity of Extreme Storms Over Time')
plt.xlabel('Year')
plt.ylabel('Maximum Sustained Wind Speed (knots)')
plt.show()

# Create a linear regression model to find the rate of increase
X = avg_intensity_per_year['year'].values.reshape(-1, 1)
y = avg_intensity_per_year['usa_wind'].values
model_q1 = LinearRegression()
model_q1.fit(X, y)
rate_of_increase = model_q1.coef_[0]
print(f"Rate of increase in intensity of extreme storms: {rate_of_increase:.4f} knots per year")
``` 

Based on the statistical analysis, the data appears to be normally distributed, as indicated by the Shapiro-Wilk test yielding a high p-value of approximately 0.184. The Pearson correlation analysis further reveals a statistically significant positive correlation between the year and the average intensity of extreme storms, with a correlation coefficient of approximately 0.654 and an extremely low p-value. This strong p-value definitively supports the conclusion that the observed positive relationship is highly unlikely to be due to random chance.

## Question 2 Analysis

### Figures and Results
* Appropriate figures illustrating your analysis and results

```{python}
# Count the number of storms per year per basin
storm_counts = df.groupby(['year', 'basin']).size().reset_index(name='storm_count')

# Pivot the data for easier plotting
storm_counts_pivot = storm_counts.pivot(index='year', columns='basin', values='storm_count').fillna(0)

# See if the data is normal for each basin
for basin in storm_counts_pivot.columns:
    stat, p_value = shapiro(storm_counts_pivot[basin])
    print(f'Shapiro-Wilk Test for {basin}: Statistics={stat}, p-value={p_value}')
    if p_value > 0.05:
        print(f"The data for {basin} is normally distributed, with p-value = {p_value}")
    else:
        print(f"The data for {basin} is not normally distributed, with p-value = {p_value}")

# Since the data is not normal, the test choice is limited to non-parametric tests.
# However, to find the rate of increase, we can still use linear regression as an approximation

# Find the rate of increase for each basin using linear regression
rates = {}
for basin in storm_counts_pivot.columns:
    X = storm_counts_pivot.index.values.reshape(-1, 1)
    y = storm_counts_pivot[basin].values
    model = LinearRegression()
    model.fit(X, y)
    rates[basin] = model.coef_[0]
    print(f"Rate of increase for {basin}: {model.coef_[0]} storms per year")

# Plot the storm counts per basin over time, add regression lines
for basin in storm_counts_pivot.columns:
    sns.regplot(x=storm_counts_pivot.index, y=storm_counts_pivot[basin], label=basin, scatter_kws={'alpha':0.5})
plt.title('Tropical Cyclone Frequency by Ocean Basin Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Storms')
plt.legend(title='Basin')
plt.show()

# Plot them as line plots for clarity
storm_counts_pivot.plot(marker='o')
plt.title('Tropical Cyclone Frequency by Ocean Basin Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Storms')
plt.legend(title='Basin')
plt.show()
``` 

## Machine Learning Model

```{python}
# Lets make a linear regression model similar to q1, but have it multiple linear regression based on basin as well.
model = LinearRegression()

# Use extreme_storms data from Q1
X = extreme_storms[['year', 'basin']]
X = pd.get_dummies(X, columns=['basin'], drop_first=True)
y = extreme_storms['usa_wind']
model.fit(X, y)

# Display coefficients
coefficients = pd.Series(model.coef_, index=X.columns)
print("Model Coefficients:")
print(coefficients)

# Model evaluation using R-squared
r_squared = model.score(X, y)
print(f"R-squared: {r_squared:.4f}")

# Predicting intensity for 1988 in the North Atlantic Basin (NAB)
year = 1988
basin = 'NAB'

predicted_intensity = model.predict(pd.DataFrame({
    'year': [year],
    **{col: [1] if col == f'basin_{basin}' else [0] for col in X.columns if col.startswith('basin_')}
}))
print(f"Predicted intensity for year {year} in basin {basin}: {predicted_intensity[0]:.2f} knots")

# Re-output the plot from Q1, but only the NAB basin with the prediction point
nab_storms = extreme_storms[extreme_storms['basin'] == 'NAB']
avg_intensity_per_year_nab = nab_storms.groupby('year')['usa_wind'].mean().reset_index()
sns.regplot(x='year', y='usa_wind', data=avg_intensity_per_year_nab, scatter_kws={'alpha':0.5})
plt.scatter(year, predicted_intensity, color='red', label='Predicted Intensity (1988, NAB)')
plt.title('Intensity of Extreme Storms in NAB Over Time')
plt.xlabel('Year')
plt.ylabel('Maximum Sustained Wind Speed (knots)')
plt.legend()
plt.show()
```

## Conclusions

Based on the statistical and machine learning analyses conducted on historical tropical cyclone data from 1970 to 2024, the following conclusions can be drawn regarding the intensity of extreme storms and the frequency of tropical cyclones across various ocean basins.

**1. Intensity of Extreme Storms**

The analysis for Research Question 1: Are the most extreme storms (top 10% in a given year) becoming more intense over time?

Definitively supports the alternative hypothesis that the intensity of the most extreme storms is increasing over time.

Statistical Significance: The Pearson correlation analysis showed a statistically significant positive correlation between the year and the average intensity of extreme storms, with a correlation coefficient of approximately 0.654 and an extremely low p-value. This p-value indicates the positive relationship is highly unlikely to be due to random chance.

Data Distribution: The data for this analysis appears to be normally distributed, supported by a Shapiro-Wilk test p-value of approximately 0.184.

Rate of Increase: The rate of increase in intensity for extreme storms is calculated to be 0.3853 knots per year.

**2. Storm Frequency by Ocean Basin**

The analysis for Research Question 2: Do the various ocean basins exhibit statistically significant differences in the rate of increase of tropical cyclone frequency?

Supports the alternative hypothesis that at least one ocean basin has a different rate of increase in tropical cyclone frequency compared to others.

Varying Rates of Change: The calculated rates of change in storm frequency (storms per year) vary significantly across different ocean basins:

Eastern Pacific (EP): 5.1217 storms per year 

North Atlantic Basin (NAB): 7.9951 storms per year

South Atlantic (SA): 8.1633 storms per year

North Indian (NI): -2.1743 storms per year

South Indian (SI): -8.2247 storms per year

South Pacific (SP): -9.3622 storms per year

Western Pacific (WP): -19.4981 storms per year

Distribution: While some basins' data (EP, NAB, WP) were found to be normally distributed based on the Shapiro-Wilk test, the data for others (NI, SA, SI, SP) were determined to be not normally distributed.

**3. Machine Learning Prediction**

A machine learning model was used to predict the intensity of extreme storms, yielding an R-squared value of 0.1334.

Prediction: The model predicted the intensity for an extreme storm in the North Atlantic Basin (NAB) in the year 1988 to be 95.29 knots.
